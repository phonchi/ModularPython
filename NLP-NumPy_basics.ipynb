{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da68091d",
      "metadata": {
        "id": "da68091d"
      },
      "source": [
        "# NLP: NumPy basics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cKfoqTemuyrN",
      "metadata": {
        "id": "cKfoqTemuyrN"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/phonchi/ModularPython/blob/master/NLP-NumPy_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/phonchi/ModularPython/blob/master/NLP-NumPy_basics.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "178ef63a",
      "metadata": {
        "id": "178ef63a"
      },
      "source": [
        "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
        "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b76dee",
      "metadata": {
        "id": "86b76dee"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Setting\n",
        "from sklearn import set_config\n",
        "np.set_printoptions(precision=2, suppress=True)\n",
        "set_config(transform_output=\"pandas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numerical Data Representation"
      ],
      "metadata": {
        "id": "zBOm21kV-NNF"
      },
      "id": "zBOm21kV-NNF"
    },
    {
      "cell_type": "markdown",
      "id": "c9399425",
      "metadata": {
        "id": "c9399425"
      },
      "source": [
        "Tables and matrices are commonly used to store data in a structured format. When dealing with purely numerical entries, these formats allow computers to process the information efficiently. However, when working with categorical or textual data, <u>transformation into numerical vectors</u> is necessary before any computational training can occur.\n",
        "\n",
        "Here's an example table showcasing how students' scores across different subjects can influence their overall decision:\n",
        "\n",
        "| Student \\ Subject | A  | B  | C  | D  | E  | Decision | Comments         |\n",
        "|-------------------|----|----|----|----|----|----------|------------------|\n",
        "| 1                 | 10 | 10 | 10 | 10 | 10 | Accept   | Excellent        |\n",
        "| 2                 | 10 | 10 | 10 | 10 | 0  | Accept   | Satisfactory     |\n",
        "| 3                 | 0  | 0  | 15 | 0  | 0  | Decline  | Needs improvement|"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc7a87d1",
      "metadata": {
        "id": "dc7a87d1"
      },
      "source": [
        "**Terminology:**\n",
        "- **Sample:** Each row represents an individual sample.\n",
        "- **Feature:** Each column represents a feature of the dataset.\n",
        "- **Vector:** A one-dimensional array of numbers.\n",
        "- **Matrix:** A two-dimensional array of numbers, stored in a rectangular format.\n",
        "- **Array:** A collection of elements stored in one or more dimensions.\n",
        "\n",
        "This format not only aids in data organization but also prepares the dataset for machine learning models where features and samples are crucial for predictions and analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d815fa4b",
      "metadata": {
        "id": "d815fa4b"
      },
      "source": [
        "### üìò NLP task: Count vector for vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f2101f5",
      "metadata": {
        "id": "3f2101f5"
      },
      "source": [
        "One way to transform a document into a vector is simply count how many times does each word occurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9bebde7",
      "metadata": {
        "id": "a9bebde7"
      },
      "outputs": [],
      "source": [
        "# Generated by ChatGPT with the question:\n",
        "# Describe \"XXX\" in simple English using less than 100 words.\n",
        "cat = \"A cat is a small furry animal with sharp claws and a long tail. They have soft fur that comes in different colors like black, white, or orange. Cats are known for their agility and ability to climb trees. They are independent creatures but can also be friendly and enjoy human companionship. They communicate through meowing and purring. Cats are often kept as pets and are loved for their playfulness and ability to catch mice.\"\n",
        "dog = \"Dogs are loyal and friendly animals that love to be around people. They come in different sizes and colors, but all dogs have fur and a wagging tail. They enjoy playing fetch, going for walks, and cuddling with their owners. Dogs are known for their keen sense of smell and hearing, which makes them great companions and protectors. They communicate through barking, wagging their tails, and using body language. Dogs are known for their unconditional love and can be part of a family, bringing happiness and companionship to their human friends.\"\n",
        "rat = \"Rats are small animals with fur and long tails. They are known for their quickness and agility. Rats can be found in various colors, such as brown, gray, or black. They are often seen scavenging for food and can squeeze through small spaces. While some people may consider them pests, rats are intelligent creatures that can learn tricks and solve problems. They have a keen sense of smell and are good at finding food. Rats are social animals and often live in groups called colonies. Despite their negative reputation, rats play a vital role in ecosystems.\"\n",
        "sun = \"The sun is a big, bright ball of light in the sky. It gives us warmth and helps plants grow. The sun rises in the morning and sets in the evening, giving us daylight. It shines during the day, making everything around us visible. The sun is very far away from us but still feels close because it is so bright. It provides us with energy and makes the world a brighter and happier place. When we feel its rays on our skin, it can feel warm and comforting. The sun is an essential part of our lives and the Earth's ecosystem.\"\n",
        "corpus = [cat, dog, rat, sun]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d7de3a",
      "metadata": {
        "id": "27d7de3a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cvec = CountVectorizer(stop_words='english', lowercase=True)\n",
        "X = cvec.fit_transform(corpus).toarray() # The default format use sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf661733",
      "metadata": {
        "id": "cf661733"
      },
      "outputs": [],
      "source": [
        "# show 10 columns only\n",
        "X[:,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d739f669",
      "metadata": {
        "id": "d739f669"
      },
      "outputs": [],
      "source": [
        "# better format by pandas\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(X)\n",
        "df.columns = cvec.get_feature_names_out()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîç Supplementary: Exploring CountVectorizer"
      ],
      "metadata": {
        "id": "kMR5XIvZ6Zds"
      },
      "id": "kMR5XIvZ6Zds"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**stop_words**: Since CountVectorizer just counts the occurrences of each word in its vocabulary, extremely common words like ‚Äòthe‚Äô, ‚Äòand‚Äô, etc. will become very important features while they add little meaning to the text. Your model can often be improved if you don‚Äôt take those words into account. Stop words are just a list of words you don‚Äôt want to use as features. You can set the parameter stop_words=‚Äôenglish‚Äô to use a built-in list. Alternatively you can set stop_words equal to some custom list. This parameter defaults to None.\n",
        "\n",
        "**ngram_range**: An n-gram is just a string of n words in a row. E.g. the sentence ‚ÄòI am Groot‚Äô contains the 2-grams ‚ÄòI am‚Äô and ‚Äòam Groot‚Äô. The sentence is itself a 3-gram. Set the parameter `ngram_range=(a,b)` where a is the minimum and b is the maximum size of ngrams you want to include in your features. The default ngram_range is (1,1). In a recent project where I modeled job postings online, I found that including 2-grams as features boosted my model‚Äôs predictive power significantly. This makes intuitive sense; many job titles such as ‚Äòdata scientist‚Äô, ‚Äòdata engineer‚Äô, and ‚Äòdata analyst‚Äô are 2 words long.\n",
        "\n",
        "**min_df, max_df**: These are the minimum and maximum document frequencies words/n-grams must have to be used as features. If either of these parameters are set to integers, they will be used as bounds on the number of documents each feature must be in to be considered as a feature. If either is set to a float, that number will be interpreted as a frequency rather than a numerical limit. min_df defaults to 1 (int) and max_df defaults to 1.0 (float).\n",
        "\n",
        "**max_features**: This parameter is pretty self-explanatory. The CountVectorizer will choose the words/features that occur most frequently to be in its‚Äô vocabulary and drop everything else."
      ],
      "metadata": {
        "id": "4lG6rI843hFe"
      },
      "id": "4lG6rI843hFe"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üí° Supplementary Code: Delve into CountVector { run: \"auto\", vertical-output: true, form-width: \"50%\" }\n",
        "vect_tunned = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.1, max_df=0.7, max_features=100)"
      ],
      "metadata": {
        "id": "4qJoUrXO30v9"
      },
      "id": "4qJoUrXO30v9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d4acf9f7",
      "metadata": {
        "id": "d4acf9f7"
      },
      "source": [
        "### Shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "981474b8",
      "metadata": {
        "id": "981474b8"
      },
      "source": [
        "NumPy is a Python package that handles arrays.  The shape of an array tells how many entries are stored in each dimension.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8e671c6",
      "metadata": {
        "id": "e8e671c6"
      },
      "outputs": [],
      "source": [
        "arr = np.zeros((3,4)) # try (3,4,5)\n",
        "print(arr.shape) # Floating point\n",
        "arr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43e7da6b",
      "metadata": {
        "id": "43e7da6b"
      },
      "source": [
        "Whenever possible, you may use `reshape` to change the shape.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "667f1c23",
      "metadata": {
        "id": "667f1c23"
      },
      "outputs": [],
      "source": [
        "arr = np.arange(12)\n",
        "arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d5e45b",
      "metadata": {
        "id": "84d5e45b"
      },
      "outputs": [],
      "source": [
        "# take a careful look of the number of brakets\n",
        "arr = np.arange(12)\n",
        "arr.reshape(3,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1467b22",
      "metadata": {
        "id": "c1467b22"
      },
      "source": [
        "Use `zeros_like` to create a zero array with the same data type.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a96a7ec",
      "metadata": {
        "id": "9a96a7ec"
      },
      "outputs": [],
      "source": [
        "arr = np.arange(12)\n",
        "arr = arr.reshape(3,4)\n",
        "print(arr.dtype)\n",
        "z_arr = np.zeros_like(arr)\n",
        "print(z_arr.dtype)\n",
        "z_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "642c2b19",
      "metadata": {
        "id": "642c2b19"
      },
      "source": [
        "### Selection and Slicing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dce3f0f",
      "metadata": {
        "id": "3dce3f0f"
      },
      "source": [
        "When `arr` is an array, use `arr[i]` or `arr[i,j]` to select its entry.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea53c94c",
      "metadata": {
        "id": "ea53c94c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "arr = np.array([1,2,3])\n",
        "print(arr)\n",
        "print(arr[2]) # Starts with 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e988d1b0",
      "metadata": {
        "id": "e988d1b0"
      },
      "outputs": [],
      "source": [
        "arr = np.arange(12).reshape(3,4)\n",
        "print(arr)\n",
        "print(arr[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c71ee290",
      "metadata": {
        "id": "c71ee290"
      },
      "outputs": [],
      "source": [
        "arr = np.arange(12).reshape(3,4)\n",
        "print(arr)\n",
        "print(arr[2,3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2ac153c",
      "metadata": {
        "id": "a2ac153c"
      },
      "source": [
        "Instead of selecting only one index `i` , you may use `a:b` to **slice** all entries from `a` to `b - 1` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cdb62e4",
      "metadata": {
        "id": "2cdb62e4"
      },
      "outputs": [],
      "source": [
        "arr = np.arange(12).reshape(3,4)\n",
        "print(arr)\n",
        "print(arr[:, 1:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a994cb",
      "metadata": {
        "id": "83a994cb"
      },
      "source": [
        "### Universal and aggregate functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "044bf940",
      "metadata": {
        "id": "044bf940"
      },
      "source": [
        "If an operation is applied to each entry, then it is called **universal** .  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482a6de5",
      "metadata": {
        "id": "482a6de5"
      },
      "outputs": [],
      "source": [
        "arr = np.arange(12).reshape(3,4)\n",
        "arr * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "581c2a6b",
      "metadata": {
        "id": "581c2a6b"
      },
      "outputs": [],
      "source": [
        "arr = np.arange(12).reshape(3,4)\n",
        "arr.sum(axis=0) # try .sum(axis=1) or .sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8379e609",
      "metadata": {
        "id": "8379e609"
      },
      "source": [
        "### Distances and similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "796d2f59",
      "metadata": {
        "id": "796d2f59"
      },
      "source": [
        "Distance metrics are fundamental in determining how close two vectors are. Consider two vectors, ${\\bf x} = (x_1, x_2, \\ldots, x_n)$ and ${\\bf y} = (y_1, y_2, \\ldots, y_n)$. The **distance** between them is computed as:\n",
        "\n",
        "$$\n",
        "    \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + \\cdots + (x_n - y_n)^2}.\n",
        "$$\n",
        "\n",
        "This expression is recognized as the **Euclidean distance** or the **$\\ell_2$-norm**.\n",
        "\n",
        "**Intuition**: This distance represents the hypotenuse of a multi-dimensional right triangle, summing up the squared differences between corresponding elements of the vectors, followed by taking the square root.\n",
        "\n",
        "**Interpretation**:\n",
        "- The distance is always non-negative ($\\geq 0$).\n",
        "- A distance of zero indicates identical vectors.\n",
        "- Larger values suggest greater disparity between the vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c09fc8",
      "metadata": {
        "id": "25c09fc8"
      },
      "outputs": [],
      "source": [
        "a = np.array([1,2,3])\n",
        "b = np.array([2,2,2])\n",
        "dist = np.sqrt(np.sum((a - b) ** 2))\n",
        "dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6463d524",
      "metadata": {
        "id": "6463d524"
      },
      "outputs": [],
      "source": [
        "# same as np.linalg.norm\n",
        "a = np.array([1,2,3])\n",
        "b = np.array([2,2,2])\n",
        "np.linalg.norm(a - b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9750c1e0",
      "metadata": {
        "id": "9750c1e0"
      },
      "source": [
        "[Cosine similarity](https://www.youtube.com/watch?v=e9U0QAFbfLI&ab_channel=StatQuestwithJoshStarmer) is another useful metric for assessing the closeness of two vectors, particularly when vectors are normalized to the unit circle (i.e., $\\|{\\bf x}\\| = 1$). This measure is extensively used in models like `word2vec`, where each word is embedded as a vector on this unit circle.\n",
        "\n",
        "Given vectors ${\\bf x} = (x_1, x_2, \\ldots, x_n)$ and ${\\bf y} = (y_1, y_2, \\ldots, y_n)$, the **cosine similarity** between them is calculated as:\n",
        "\n",
        "$$\n",
        "    \\cos\\theta = \\frac{{\\bf x}\\cdot{\\bf y}}{\\|{\\bf x}\\|\\|{\\bf y}\\|},\n",
        "$$\n",
        "\n",
        "where $\\cos\\theta$ is the cosine of the angle $\\theta$ between the vectors, and ${\\bf x}\\cdot{\\bf y} = x_1y_1 + x_2y_2 + \\cdots + x_ny_n$ represents the **dot product**.\n",
        "\n",
        "**Intuition**: Cosine similarity measures the cosine of the angle between two vectors, providing a measure of their directional alignment.\n",
        "\n",
        "**Interpretation**:\n",
        "- The value ranges from $-1$ to $1$.\n",
        "- A similarity of $1$ indicates that the two vectors are in the same direction.\n",
        "- A similarity of $0$ suggests orthogonality, implying independence.\n",
        "- A similarity of $-1$ means the vectors are in opposite directions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49a87161",
      "metadata": {
        "id": "49a87161"
      },
      "outputs": [],
      "source": [
        "a = np.array([0.6, 0.8,   0])\n",
        "b = np.array([0.6,   0, 0.8])\n",
        "\n",
        "def cosine_similarity(x, y):\n",
        "    return np.dot(x, y) / np.linalg.norm(x) / np.linalg.norm(y)\n",
        "\n",
        "cosine_similarity(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a00f2b5",
      "metadata": {
        "id": "5a00f2b5"
      },
      "source": [
        "### üìò NLP task: how similar are two documents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59ba3e2f",
      "metadata": {
        "id": "59ba3e2f"
      },
      "source": [
        "[TF-IDF (Term Frequency-Inverse Document Frequency)](https://www.youtube.com/watch?v=zLMEnNbdh4Q&ab_channel=DataMListic) is a statistical measure used to evaluate the importance of a word in a document, relative to a collection of documents or corpus. The computation of TF-IDF is performed as follows:\n",
        "\n",
        "1. **Term Frequency (TF)** measures how frequently a term occurs in a document. It is calculated by:\n",
        "   $$\n",
        "   \\operatorname{tf}(\\text{doc}_i, \\text{word}_j) = \\frac{\\text{# of occurrences of word}_j \\text{ in doc}_i}{\\text{# of words in doc}_i}\n",
        "   $$\n",
        "\n",
        "2. **Document Frequency (DF)** assesses how common a word is across all documents. It is defined as:\n",
        "   $$\n",
        "   \\operatorname{df}(\\text{word}_j) = \\frac{\\text{# of documents containing word}_j}{\\text{# of documents}}\n",
        "   $$\n",
        "\n",
        "3. **TF-IDF** is then calculated by:\n",
        "   $$\n",
        "   \\operatorname{tf-idf}(\\text{doc}_i, \\text{word}_j) = \\operatorname{tf}(\\text{doc}_i, \\text{word}_j) \\times \\log_2 \\left(\\frac{1}{\\operatorname{df}(\\text{word}_j)}\\right)\n",
        "   $$\n",
        "\n",
        "Modifications to the formula include adding one to the denominators to avoid division by zero when a word does not appear in any documents.\n",
        "\n",
        "**Intuition**: A high term frequency indicates that a word is important within a specific document. Conversely, a high document frequency suggests that the word is common (e.g. functional word) and perhaps less significant across all documents.\n",
        "\n",
        "**Interpretation**:\n",
        "- TF-IDF values are non-negative ($\\geq 0$).\n",
        "- A value of zero indicates that the word does not appear in the document.\n",
        "- Higher TF-IDF values signify greater importance of the word within the document in relation to the entire corpus.\n",
        "\n",
        "This method is highly effective in filtering out common terms while highlighting significant terms specific to a document, making it essential for document analysis and information retrieval systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b613a4c",
      "metadata": {
        "id": "2b613a4c"
      },
      "outputs": [],
      "source": [
        "# Generat,ed by ChatGPT with the question:\n",
        "# Describe \"XXX\" in simple English using less than 100 words.\n",
        "cat = \"A cat is a small furry animal with sharp claws and a long tail. They have soft fur that comes in different colors like black, white, or orange. Cats are known for their agility and ability to climb trees. They are independent creatures but can also be friendly and enjoy human companionship. They communicate through meowing and purring. Cats are often kept as pets and are loved for their playfulness and ability to catch mice.\"\n",
        "dog = \"Dogs are loyal and friendly animals that love to be around people. They come in different sizes and colors, but all dogs have fur and a wagging tail. They enjoy playing fetch, going for walks, and cuddling with their owners. Dogs are known for their keen sense of smell and hearing, which makes them great companions and protectors. They communicate through barking, wagging their tails, and using body language. Dogs are known for their unconditional love and can be part of a family, bringing happiness and companionship to their human friends.\"\n",
        "rat = \"Rats are small animals with fur and long tails. They are known for their quickness and agility. Rats can be found in various colors, such as brown, gray, or black. They are often seen scavenging for food and can squeeze through small spaces. While some people may consider them pests, rats are intelligent creatures that can learn tricks and solve problems. They have a keen sense of smell and are good at finding food. Rats are social animals and often live in groups called colonies. Despite their negative reputation, rats play a vital role in ecosystems.\"\n",
        "sun = \"The sun is a big, bright ball of light in the sky. It gives us warmth and helps plants grow. The sun rises in the morning and sets in the evening, giving us daylight. It shines during the day, making everything around us visible. The sun is very far away from us but still feels close because it is so bright. It provides us with energy and makes the world a brighter and happier place. When we feel its rays on our skin, it can feel warm and comforting. The sun is an essential part of our lives and the Earth's ecosystem.\"\n",
        "corpus = [cat, dog, rat, sun]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9489d398",
      "metadata": {
        "id": "9489d398"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "X = tfidf.fit_transform(corpus).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02141130",
      "metadata": {
        "id": "02141130"
      },
      "outputs": [],
      "source": [
        "# show 10 columns only\n",
        "X[:,:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52d1f253",
      "metadata": {
        "id": "52d1f253"
      },
      "source": [
        "Now `X[0], ..., X[3]` are the vector representations of the four documents, cat, dog, rat, and sun.  We may calculate their pairwise distances and cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc52b4ac",
      "metadata": {
        "id": "fc52b4ac"
      },
      "outputs": [],
      "source": [
        "# cosine similarity\n",
        "def cosine_similarity(x, y):\n",
        "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
        "\n",
        "cosine_similarity(X[0], X[1]) # try other pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "043a6cea",
      "metadata": {
        "id": "043a6cea"
      },
      "source": [
        "When each row is of length one, the formula `X.dot(X.T)` calculates the pairwise cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7472b896",
      "metadata": {
        "id": "7472b896"
      },
      "outputs": [],
      "source": [
        "X.dot(X.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b4a50f6",
      "metadata": {
        "id": "7b4a50f6"
      },
      "outputs": [],
      "source": [
        "# distance\n",
        "np.linalg.norm(X[0] - X[1]) # try other pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b8c588",
      "metadata": {
        "id": "29b8c588"
      },
      "source": [
        "We may use `pairwise_distances` function in `sklearn` to calculate the pairwise distances at once.  It looks like the document of sun is farther away from the other three documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06183de5",
      "metadata": {
        "id": "06183de5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import pairwise_distances\n",
        "pairwise_distances(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f9b029b",
      "metadata": {
        "id": "0f9b029b"
      },
      "source": [
        "### üîç Supplementary: `TfidfTransformer` apply the following transformation to the count matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb365b97",
      "metadata": {
        "id": "fb365b97"
      },
      "outputs": [],
      "source": [
        "# count matrix\n",
        "a = np.array([[1,1,2,1],\n",
        "        [1,2,0,0],\n",
        "        [2,2,0,0]])\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "model = TfidfTransformer()\n",
        "tfidf_mtx = model.fit_transform(a).toarray()\n",
        "tfidf_mtx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m7UcYPVDXCnl",
      "metadata": {
        "id": "m7UcYPVDXCnl"
      },
      "source": [
        "Now, we manually calculate it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9494a2a",
      "metadata": {
        "id": "e9494a2a"
      },
      "outputs": [],
      "source": [
        "# calculate tf\n",
        "tf = a / a.sum(axis=1)[:,np.newaxis]\n",
        "tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d497fde5",
      "metadata": {
        "id": "d497fde5"
      },
      "outputs": [],
      "source": [
        "# calculate idf\n",
        "idf = np.log( (a.shape[0] + 1) / ((a > 0).sum(axis=0) + 1) ) + 1\n",
        "idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac2cfc7d",
      "metadata": {
        "id": "ac2cfc7d"
      },
      "outputs": [],
      "source": [
        "# create tf-idf and normalize each row\n",
        "w = tf * idf\n",
        "w / np.linalg.norm(w, axis=1)[:,np.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lZPzsM3KXuXb",
      "metadata": {
        "id": "lZPzsM3KXuXb"
      },
      "source": [
        "### üîç Supplementary: Use `CountVectorize` and `TfidfTransformer` to obtain the tf-idf vectorization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CSOpAi6vXykS",
      "metadata": {
        "id": "CSOpAi6vXykS"
      },
      "outputs": [],
      "source": [
        "# @title üí° Supplementary Code: Use TF-IDF Transformer { run: \"auto\", vertical-output: true, form-width: \"50%\" }\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "X1 = tfidf.fit_transform(corpus).toarray()\n",
        "\n",
        "cvec = CountVectorizer(stop_words='english')\n",
        "X2 = cvec.fit_transform(corpus)\n",
        "model = TfidfTransformer()\n",
        "tfidf_mtx = model.fit_transform(X2).toarray()\n",
        "\n",
        "np.testing.assert_array_equal(X1, tfidf_mtx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edb5bdf0",
      "metadata": {
        "id": "edb5bdf0"
      },
      "source": [
        "### üìö Further reading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6717f14a",
      "metadata": {
        "id": "6717f14a"
      },
      "source": [
        "- [_Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/) by Jake VanderPlas"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "kMR5XIvZ6Zds"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
